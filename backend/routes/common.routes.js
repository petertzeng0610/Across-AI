// backend/routes/common.routes.js
// é€šç”¨ API è·¯ç”±ï¼ˆä¸ç‰¹å®šæ–¼ä»»ä½•ç”¢å“ï¼‰

const express = require('express');
const router = express.Router();
const { GoogleGenerativeAI } = require('@google/generative-ai');

// ç²å–å¯ç”¨çš„ AI æ¨¡å‹åˆ—è¡¨
router.get('/models', (_req, res) => {
  res.json({ 
    models: ['gemini-2.0-flash-exp', 'gemini-1.5-flash', 'gemini-1.5-pro'] 
  });
});

// æ¸¬è©¦ AI é€£æ¥ï¼ˆGemini æˆ– Ollamaï¼‰
router.post('/test-ai', async (req, res) => {
  try {
    const { apiKey, model = 'gemini-2.0-flash-exp', aiProvider = 'gemini' } = req.body;
    
    console.log(`\nğŸ§ª æ¸¬è©¦ ${aiProvider === 'ollama' ? 'Ollama' : 'Gemini'} AI é€£æ¥...`);
    console.log(`ğŸ¤– æ¨¡å‹: ${model}`);
    
    const testPrompt = 'è«‹ç”¨ç¹é«”ä¸­æ–‡ç°¡å–®å›ç­”ï¼šä½ æ˜¯èª°ï¼Ÿ';
    let responseText;
    
    if (aiProvider === 'ollama') {
      // æ¸¬è©¦ Ollama
      if (!model) {
        return res.status(400).json({ 
          error: 'è«‹æŒ‡å®š Ollama æ¨¡å‹åç¨±',
          example: 'gpt-oss:20b'
        });
      }
      
      const ollamaUrl = process.env.OLLAMA_URL || 'http://localhost:11434';
      console.log(`ğŸ¦™ Ollama URL: ${ollamaUrl}`);
      
      // å…ˆæª¢æŸ¥ Ollama æœå‹™æ˜¯å¦å¯ç”¨
      try {
        const healthCheck = await fetch(`${ollamaUrl}/api/tags`);
        if (!healthCheck.ok) {
          throw new Error(`Ollama æœå‹™ä¸å¯ç”¨: ${healthCheck.status}`);
        }
        const modelsData = await healthCheck.json();
        console.log(`âœ… Ollama æœå‹™æ­£å¸¸ï¼Œå¯ç”¨æ¨¡å‹: ${modelsData.models?.map(m => m.name).join(', ') || 'ç„¡'}`);
      } catch (healthError) {
        return res.status(503).json({
          error: 'Ollama æœå‹™é€£æ¥å¤±æ•—',
          details: healthError.message,
          ollamaUrl,
          suggestion: 'è«‹ç¢ºèª Ollama å·²å•Ÿå‹•ï¼Œä¸¦ä¸”å¯ä»¥åœ¨ ' + ollamaUrl + ' å­˜å–'
        });
      }
      
      // åŸ·è¡Œæ¸¬è©¦ç”Ÿæˆ
      const ollamaResponse = await fetch(`${ollamaUrl}/api/generate`, {
        method: 'POST',
        headers: {
          'Content-Type': 'application/json',
        },
        body: JSON.stringify({
          model,
          prompt: testPrompt,
          stream: false,
          options: {
            temperature: 0.7,
            num_predict: 100
          }
        })
      });
      
      if (!ollamaResponse.ok) {
        const errorText = await ollamaResponse.text();
        throw new Error(`Ollama API éŒ¯èª¤ (${ollamaResponse.status}): ${errorText}`);
      }
      
      const ollamaData = await ollamaResponse.json();
      responseText = ollamaData.response;
      
      console.log(`âœ… Ollama å›æ‡‰: ${responseText.substring(0, 100)}...`);
      
      res.json({ 
        success: true,
        aiProvider: 'ollama',
        model,
        ollamaUrl,
        response: responseText,
        message: 'Ollama AI é€£æ¥æ¸¬è©¦æˆåŠŸ'
      });
      
    } else {
      // æ¸¬è©¦ Gemini
      if (!apiKey) {
        return res.status(400).json({ 
          error: 'è«‹æä¾› Gemini API Key' 
        });
      }
      
      const genAI = new GoogleGenerativeAI(apiKey);
      const geminiModel = genAI.getGenerativeModel({ model });
      const result = await geminiModel.generateContent(testPrompt);
      responseText = result.response.text();
      
      console.log(`âœ… Gemini å›æ‡‰: ${responseText.substring(0, 100)}...`);
      
      res.json({ 
        success: true,
        aiProvider: 'gemini',
        model,
        response: responseText,
        message: 'Gemini AI é€£æ¥æ¸¬è©¦æˆåŠŸ'
      });
    }
    
  } catch (error) {
    console.error('âŒ AI é€£æ¥æ¸¬è©¦å¤±æ•—:', error);
    res.status(500).json({ 
      success: false,
      error: 'AI é€£æ¥æ¸¬è©¦å¤±æ•—',
      details: error.message
    });
  }
});

module.exports = router;


